# SmartSuccess.AI GPU Integration Guide

## Overview

This project now supports a hybrid architecture with:
- **Render Backend** (Always On): User management, payments, basic interview services
- **GPU Server** (When Available): Advanced voice processing, RAG, embeddings

The frontend automatically routes requests to the appropriate backend based on availability.

## Environment Variables

### Frontend (Vercel)

Add these environment variables in your Vercel dashboard:

```bash
# Existing backend (Render)
NEXT_PUBLIC_BACKEND_URL=https://smartsuccess-ai.onrender.com

# GPU backend (optional - for enhanced features)
NEXT_PUBLIC_GPU_BACKEND_URL=https://your-gpu-server.inference.ai

# Render backend URL (fallback, defaults to NEXT_PUBLIC_BACKEND_URL)
NEXT_PUBLIC_RENDER_BACKEND_URL=https://smartsuccess-ai.onrender.com
```

### GPU Backend Server

Create a `.env` file in the `gpu_backend/` directory:

```bash
# Application
APP_NAME=SmartSuccess.AI GPU Backend
APP_VERSION=1.0.0
DEBUG=false
ENVIRONMENT=production

# Server
HOST=0.0.0.0
PORT=8000
WORKERS=4

# CORS - Add your frontend domains
ALLOWED_ORIGINS=["https://smart-success-ai.vercel.app","https://matchwise-ai.vercel.app","http://localhost:3000"]

# Render backend for fallback
RENDER_BACKEND_URL=https://smartsuccess-ai.onrender.com

# Optional: API keys if using external services
OPENAI_API_KEY=
GROQ_API_KEY=

# Data paths
DATA_DIR=./data
PRERAG_DIR=./data/pre_rag
USER_RAG_DIR=./data/user_rag
VOICE_PRESETS_DIR=./data/voice_presets

# GPU settings
GPU_DEVICE=cuda
GPU_MEMORY_FRACTION=0.9
```

## Architecture

```
Frontend (Vercel)
    â”‚
    â”œâ”€â†’ Request Router (requestRouter.ts)
    â”‚       â”‚
    â”‚       â”œâ”€â†’ GPU Server (when available)
    â”‚       â”‚   â€¢ Voice processing (Whisper + XTTS)
    â”‚       â”‚   â€¢ Advanced RAG
    â”‚       â”‚   â€¢ GPU embeddings
    â”‚       â”‚
    â”‚       â””â”€â†’ Render Backend (fallback)
    â”‚           â€¢ User management
    â”‚           â€¢ Payments
    â”‚           â€¢ Basic interview
```

## Request Routing

The frontend automatically routes requests:

- **Always to Render**: `/auth`, `/payment`, `/user`, `/visitor`
- **Prefer GPU**: `/api/voice/*`, `/api/rag/*`, `/api/embedding/*`
- **Hybrid** (GPU if available): `/api/interview/*`

## Features

### GPU-Enhanced Features (When GPU Server Online)

- âœ… Whisper Large-v3 for speech recognition
- âœ… XTTS-v2 for natural text-to-speech
- âœ… GPU-accelerated embeddings
- âœ… Pre-trained RAG question bank (5000+ questions)
- âœ… Personalized RAG from MatchWise.ai integration

### Fallback Features (When GPU Server Offline)

- âœ… Web Speech API for speech recognition
- âœ… Browser TTS for text-to-speech
- âœ… Standard interview functionality
- âœ… All basic features remain available

## Deployment

### GPU Backend Deployment

1. **SSH to GPU server**
   ```bash
   ssh user@gpu.inference.ai
   ```

2. **Navigate to GPU backend**
   ```bash
   cd smartsuccess-gpu-enhancement/gpu_backend
   ```

3. **Install dependencies**
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```

4. **Configure environment**
   ```bash
   nano .env
   ```

5. **Start server**
   ```bash
   source venv/bin/activate
   uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
   ```

### Frontend Deployment

No changes needed! The frontend automatically detects GPU availability and routes requests accordingly.

## Testing

### Test GPU Server

```bash
# Health check
curl https://your-gpu-server/health

# Expected response:
# {"status":"healthy","gpu_available":true,...}
```

### Test Frontend Integration

1. Open browser console
2. Navigate to interview page
3. Check for GPU status logs:
   - `ğŸ–¥ï¸ GPU server health: Available` (good)
   - `âš ï¸ GPU server unreachable` (fallback mode)

4. Verify GPU status badge shows:
   - "GPU Enhanced" when GPU is available
   - "Standard Mode" when GPU is offline

## Troubleshooting

### GPU Not Detected

1. Check GPU server is running: `curl https://your-gpu-server/health`
2. Verify `NEXT_PUBLIC_GPU_BACKEND_URL` is set correctly
3. Check browser console for routing logs

### Fallback Not Working

1. Verify `NEXT_PUBLIC_RENDER_BACKEND_URL` is set
2. Check that Render backend is accessible
3. Review request router logs in console

### CORS Errors

Update `ALLOWED_ORIGINS` in GPU backend `.env`:
```bash
ALLOWED_ORIGINS=["https://your-domain.vercel.app","http://localhost:3000"]
```

## Backward Compatibility

âœ… **All existing functionality is preserved**
- Existing API calls continue to work
- Render backend remains the primary backend
- GPU features are optional enhancements
- Automatic fallback ensures no service interruption

## File Structure

```
resume-matcher-frontend/
â”œâ”€â”€ src/app/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ requestRouter.ts          # Smart routing logic
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useGPUBackend.ts          # GPU backend hook
â”‚   â”‚   â””â”€â”€ useVoiceInterview.ts      # Voice interview hook
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ GPUStatusIndicator.tsx    # GPU status display
â”‚   â””â”€â”€ interview/
â”‚       â””â”€â”€ page.tsx                  # Updated with GPU support
â”‚
smartsuccess-gpu-enhancement/
â””â”€â”€ gpu_backend/                      # Independent GPU server
    â”œâ”€â”€ main.py
    â”œâ”€â”€ services/
    â”œâ”€â”€ routes/
    â””â”€â”€ config/
```

## Support

For issues:
1. Check GPU server logs
2. Check browser console for routing errors
3. Verify environment variables are set correctly
4. Review health endpoint: `/health`
